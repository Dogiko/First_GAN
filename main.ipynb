{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def circle_generator(num = 1):\n",
    "    # generate circle with radiu (4,16) and center (0, 64)x(0, 64)\n",
    "    _idx = np.zeros((2,64,64))\n",
    "    _idx[0] = np.arange(64).reshape(64,1).repeat(64, axis = 1)\n",
    "    _idx[1] = _idx[0].T\n",
    "    \n",
    "    output = np.zeros((num, 1, 64, 64))\n",
    "    \n",
    "    centers = 32*np.random.rand(num, 2) + 16\n",
    "    square_radius = np.square(12*np.random.rand(num) + 4)\n",
    "    \n",
    "    for n in range(num):\n",
    "        output[n, 0] = (np.square(_idx[0] - centers[n, 0]) + np.square(_idx[1] - centers[n, 1]) <= square_radius[n])\n",
    "    \n",
    "    output = torch.tensor(output.astype(np.float32))\n",
    "    return output\n",
    "\n",
    "class GNet(nn.Module):\n",
    "    # generator\n",
    "    def __init__(self):\n",
    "        super(GNet, self).__init__()\n",
    "        self.conv_trans_2d1 = nn.ConvTranspose2d(128, 64, 9)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv_trans_2d2 = nn.ConvTranspose2d(64, 32, 9)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv_trans_2d3 = nn.ConvTranspose2d(32, 16, 9)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        self.conv_trans_2d4 = nn.ConvTranspose2d(16, 1, 9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv_trans_2d1(x)))\n",
    "        x = F.relu(self.bn2(self.conv_trans_2d2(x)))\n",
    "        x = F.relu(self.bn3(self.conv_trans_2d3(x)))\n",
    "        x = torch.sigmoid(self.conv_trans_2d4(x))\n",
    "        return x\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    # discriminator\n",
    "    def __init__(self):\n",
    "        super(DNet, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5) # (64 - 4)/2 = 30\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3) # (30 - 2)/2 = 14\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 100)\n",
    "        self.fc2 = nn.Linear(100, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 14 * 14)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "def d_criterion(outputs, labels):\n",
    "    modify_outputs = 0.01 + outputs*0.98\n",
    "    return -(labels*torch.log(modify_outputs) + (1-labels)*torch.log(1-modify_outputs)).mean()\n",
    "\n",
    "def g_criterion(fack_object):\n",
    "    return -torch.log(0.01 + 0.98*discriminator(fack_object)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datum_num = 500\n",
    "\n",
    "d_epoch = 3\n",
    "g_epoch = 3\n",
    "\n",
    "generator = GNet()\n",
    "discriminator = DNet()\n",
    "\n",
    "true_circles = circle_generator(datum_num)\n",
    "fake_circles = generator(2*torch.rand(datum_num, 128, 32, 32)-1).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round : 1, d_train epoch : 1, loss: 0.051\n",
      "round : 1, d_train epoch : 2, loss: 0.010\n",
      "round : 1, d_train epoch : 3, loss: 0.010\n",
      "round : 1, g_train epoch : 1, loss: 0.216\n",
      "round : 1, g_train epoch : 2, loss: 0.010\n",
      "round : 1, g_train epoch : 3, loss: 0.010\n",
      "round : 2, d_train epoch : 1, loss: 0.055\n",
      "round : 2, d_train epoch : 2, loss: 0.010\n",
      "round : 2, d_train epoch : 3, loss: 0.010\n",
      "round : 2, g_train epoch : 1, loss: 0.235\n",
      "round : 2, g_train epoch : 2, loss: 0.010\n",
      "round : 2, g_train epoch : 3, loss: 0.010\n",
      "round : 3, d_train epoch : 1, loss: 0.157\n",
      "round : 3, d_train epoch : 2, loss: 0.011\n",
      "round : 3, d_train epoch : 3, loss: 0.011\n",
      "round : 3, g_train epoch : 1, loss: 0.062\n",
      "round : 3, g_train epoch : 2, loss: 0.010\n",
      "round : 3, g_train epoch : 3, loss: 0.010\n",
      "round : 4, d_train epoch : 1, loss: 0.048\n",
      "round : 4, d_train epoch : 2, loss: 0.011\n",
      "round : 4, d_train epoch : 3, loss: 0.010\n",
      "round : 4, g_train epoch : 1, loss: 0.181\n",
      "round : 4, g_train epoch : 2, loss: 0.010\n",
      "round : 4, g_train epoch : 3, loss: 0.010\n",
      "round : 5, d_train epoch : 1, loss: 0.096\n",
      "round : 5, d_train epoch : 2, loss: 0.011\n",
      "round : 5, d_train epoch : 3, loss: 0.011\n",
      "round : 5, g_train epoch : 1, loss: 0.174\n",
      "round : 5, g_train epoch : 2, loss: 0.011\n",
      "round : 5, g_train epoch : 3, loss: 0.010\n",
      "round : 6, d_train epoch : 1, loss: 0.096\n",
      "round : 6, d_train epoch : 2, loss: 0.021\n",
      "round : 6, d_train epoch : 3, loss: 0.016\n",
      "round : 6, g_train epoch : 1, loss: 0.348\n",
      "round : 6, g_train epoch : 2, loss: 0.018\n",
      "round : 6, g_train epoch : 3, loss: 0.014\n",
      "round : 7, d_train epoch : 1, loss: 0.124\n",
      "round : 7, d_train epoch : 2, loss: 0.024\n",
      "round : 7, d_train epoch : 3, loss: 0.019\n",
      "round : 7, g_train epoch : 1, loss: 0.239\n",
      "round : 7, g_train epoch : 2, loss: 0.011\n",
      "round : 7, g_train epoch : 3, loss: 0.010\n",
      "round : 8, d_train epoch : 1, loss: 0.055\n",
      "round : 8, d_train epoch : 2, loss: 0.038\n",
      "round : 8, d_train epoch : 3, loss: 0.035\n",
      "round : 8, g_train epoch : 1, loss: 0.285\n",
      "round : 8, g_train epoch : 2, loss: 0.082\n",
      "round : 8, g_train epoch : 3, loss: 0.081\n",
      "round : 9, d_train epoch : 1, loss: 0.082\n",
      "round : 9, d_train epoch : 2, loss: 0.029\n",
      "round : 9, d_train epoch : 3, loss: 0.020\n",
      "round : 9, g_train epoch : 1, loss: 0.284\n",
      "round : 9, g_train epoch : 2, loss: 0.020\n",
      "round : 9, g_train epoch : 3, loss: 0.011\n",
      "round : 10, d_train epoch : 1, loss: 0.191\n",
      "round : 10, d_train epoch : 2, loss: 0.102\n",
      "round : 10, d_train epoch : 3, loss: 0.028\n",
      "round : 10, g_train epoch : 1, loss: 0.927\n",
      "round : 10, g_train epoch : 2, loss: 0.087\n",
      "round : 10, g_train epoch : 3, loss: 0.036\n",
      "round : 11, d_train epoch : 1, loss: 0.186\n",
      "round : 11, d_train epoch : 2, loss: 0.042\n",
      "round : 11, d_train epoch : 3, loss: 0.023\n",
      "round : 11, g_train epoch : 1, loss: 0.954\n",
      "round : 11, g_train epoch : 2, loss: 0.107\n",
      "round : 11, g_train epoch : 3, loss: 0.065\n",
      "round : 12, d_train epoch : 1, loss: 0.102\n",
      "round : 12, d_train epoch : 2, loss: 0.036\n",
      "round : 12, d_train epoch : 3, loss: 0.032\n",
      "round : 12, g_train epoch : 1, loss: 2.658\n",
      "round : 12, g_train epoch : 2, loss: 2.142\n",
      "round : 12, g_train epoch : 3, loss: 2.001\n",
      "round : 13, d_train epoch : 1, loss: 0.146\n",
      "round : 13, d_train epoch : 2, loss: 0.058\n",
      "round : 13, d_train epoch : 3, loss: 0.057\n",
      "round : 13, g_train epoch : 1, loss: 1.686\n",
      "round : 13, g_train epoch : 2, loss: 0.784\n",
      "round : 13, g_train epoch : 3, loss: 0.012\n",
      "round : 14, d_train epoch : 1, loss: 0.070\n",
      "round : 14, d_train epoch : 2, loss: 0.041\n",
      "round : 14, d_train epoch : 3, loss: 0.046\n",
      "round : 14, g_train epoch : 1, loss: 1.786\n",
      "round : 14, g_train epoch : 2, loss: 0.901\n",
      "round : 14, g_train epoch : 3, loss: 0.429\n",
      "round : 15, d_train epoch : 1, loss: 0.063\n",
      "round : 15, d_train epoch : 2, loss: 0.051\n",
      "round : 15, d_train epoch : 3, loss: 0.048\n",
      "round : 15, g_train epoch : 1, loss: 2.530\n",
      "round : 15, g_train epoch : 2, loss: 1.345\n",
      "round : 15, g_train epoch : 3, loss: 1.184\n",
      "round : 16, d_train epoch : 1, loss: 0.113\n",
      "round : 16, d_train epoch : 2, loss: 0.059\n",
      "round : 16, d_train epoch : 3, loss: 0.034\n",
      "round : 16, g_train epoch : 1, loss: 1.103\n",
      "round : 16, g_train epoch : 2, loss: 0.391\n",
      "round : 16, g_train epoch : 3, loss: 0.075\n",
      "round : 17, d_train epoch : 1, loss: 0.111\n",
      "round : 17, d_train epoch : 2, loss: 0.054\n",
      "round : 17, d_train epoch : 3, loss: 0.093\n",
      "round : 17, g_train epoch : 1, loss: 1.443\n",
      "round : 17, g_train epoch : 2, loss: 0.112\n",
      "round : 17, g_train epoch : 3, loss: 0.047\n",
      "round : 18, d_train epoch : 1, loss: 0.115\n",
      "round : 18, d_train epoch : 2, loss: 0.050\n",
      "round : 18, d_train epoch : 3, loss: 0.040\n",
      "round : 18, g_train epoch : 1, loss: 2.553\n",
      "round : 18, g_train epoch : 2, loss: 1.567\n",
      "round : 18, g_train epoch : 3, loss: 1.520\n",
      "round : 19, d_train epoch : 1, loss: 0.149\n",
      "round : 19, d_train epoch : 2, loss: 0.090\n",
      "round : 19, d_train epoch : 3, loss: 0.092\n",
      "round : 19, g_train epoch : 1, loss: 2.533\n",
      "round : 19, g_train epoch : 2, loss: 2.114\n",
      "round : 19, g_train epoch : 3, loss: 2.002\n",
      "round : 20, d_train epoch : 1, loss: 0.262\n",
      "round : 20, d_train epoch : 2, loss: 0.136\n",
      "round : 20, d_train epoch : 3, loss: 0.099\n",
      "round : 20, g_train epoch : 1, loss: 2.135\n",
      "round : 20, g_train epoch : 2, loss: 1.987\n",
      "round : 20, g_train epoch : 3, loss: 2.149\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "rounds = 20\n",
    "for r in range(rounds):\n",
    "    true_circles = true_circles[torch.randperm(datum_num)]\n",
    "    true_circles[int(0.8*datum_num):] = circle_generator(datum_num - int(0.8*datum_num))\n",
    "    fake_circles = fake_circles[torch.randperm(datum_num)]\n",
    "    fake_circles[int(0.8*datum_num):] = generator(2*torch.rand(datum_num - int(0.8*datum_num), 128, 32, 32)-1).data\n",
    "    circles = torch.cat((true_circles, fake_circles), 0)\n",
    "\n",
    "    labels = torch.cat((torch.ones((datum_num, 1)), torch.zeros((datum_num, 1))), 0)\n",
    "\n",
    "    d_data_set = torch.utils.data.TensorDataset(circles, labels)\n",
    "    d_trainloader = torch.utils.data.DataLoader(d_data_set, batch_size=10, shuffle=True, num_workers=2)\n",
    "\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr = 0.001, weight_decay = 0.0001)\n",
    "\n",
    "    for e in range(d_epoch):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(d_trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            d_optimizer.zero_grad()\n",
    "            outputs = discriminator(inputs)\n",
    "            loss = d_criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            d_optimizer.step()\n",
    "            running_loss += loss.data\n",
    "    \n",
    "        print('round : %i, d_train epoch : %d, loss: %.3f' %(r + 1, e + 1 , running_loss / 100))\n",
    "\n",
    "\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(), lr = 0.001, weight_decay=0.0001)\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for e in range(g_epoch):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i in range(int(2*datum_num/10)):\n",
    "            inputs = 2*torch.rand(10, 128, 32,32)-1\n",
    "            g_optimizer.zero_grad()\n",
    "            outputs = generator(inputs)\n",
    "            loss = g_criterion(outputs)\n",
    "            loss.backward()\n",
    "            g_optimizer.step()\n",
    "            running_loss += loss.data\n",
    "\n",
    "        print('round : %i, g_train epoch : %d, loss: %.3f' %(r + 1, e + 1 , running_loss / 100))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZPClBv0fUISRP89td40AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16271ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(generator(2*torch.rand(1,128, 32, 32)-1).data[0,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
